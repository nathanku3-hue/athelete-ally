// ELK Stack æ—¥å¿—èšåˆå®ç°è„šæœ¬
import fs from 'fs';
import path from 'path';

const setupELKStack = () => {
  console.log('ğŸ“Š å¼€å§‹ELK Stackæ—¥å¿—èšåˆè®¾ç½®...\n');
  
  // 1. åˆ›å»ºELK Stacké…ç½®
  const elkConfig = {
    // Elasticsearché…ç½®
    elasticsearch: {
      version: '8.11.0',
      port: 9200,
      cluster: 'athlete-ally-cluster',
      node: 'athlete-ally-node',
      memory: '2g',
      indices: {
        planning_engine: {
          shards: 1,
          replicas: 0,
          refresh_interval: '5s'
        },
        monitoring: {
          shards: 1,
          replicas: 0,
          refresh_interval: '1s'
        }
      }
    },
    
    // Logstashé…ç½®
    logstash: {
      version: '8.11.0',
      port: 5044,
      pipelines: [
        {
          name: 'planning-engine-logs',
          input: 'beats',
          filter: 'grok',
          output: 'elasticsearch'
        },
        {
          name: 'monitoring-logs',
          input: 'beats',
          filter: 'json',
          output: 'elasticsearch'
        }
      ]
    },
    
    // Kibanaé…ç½®
    kibana: {
      version: '8.11.0',
      port: 5601,
      elasticsearch: 'http://elasticsearch:9200',
      dashboards: [
        'planning-engine-dashboard',
        'monitoring-dashboard',
        'security-dashboard'
      ]
    },
    
    // Filebeaté…ç½®
    filebeat: {
      version: '8.11.0',
      inputs: [
        {
          type: 'log',
          enabled: true,
          paths: ['/var/log/planning-engine/*.log'],
          fields: {
            service: 'planning-engine',
            environment: 'production'
          }
        },
        {
          type: 'log',
          enabled: true,
          paths: ['/var/log/monitoring/*.log'],
          fields: {
            service: 'monitoring',
            environment: 'production'
          }
        }
      ],
      output: {
        logstash: {
          hosts: ['logstash:5044']
        }
      }
    }
  };
  
  // 2. åˆ›å»ºDocker Composeé…ç½®
  const dockerCompose = `
version: '3.8'

services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: athlete-ally-elasticsearch
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms2g -Xmx2g"
      - xpack.security.enabled=false
    ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    networks:
      - elk-network
    restart: unless-stopped

  logstash:
    image: docker.elastic.co/logstash/logstash:8.11.0
    container_name: athlete-ally-logstash
    ports:
      - "5044:5044"
      - "9600:9600"
    volumes:
      - ./elk/logstash/pipeline:/usr/share/logstash/pipeline
      - ./elk/logstash/config:/usr/share/logstash/config
    environment:
      - "LS_JAVA_OPTS=-Xmx1g -Xms1g"
    depends_on:
      - elasticsearch
    networks:
      - elk-network
    restart: unless-stopped

  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    container_name: athlete-ally-kibana
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    depends_on:
      - elasticsearch
    networks:
      - elk-network
    restart: unless-stopped

  filebeat:
    image: docker.elastic.co/beats/filebeat:8.11.0
    container_name: athlete-ally-filebeat
    user: root
    volumes:
      - ./elk/filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - /var/log/planning-engine:/var/log/planning-engine:ro
      - /var/log/monitoring:/var/log/monitoring:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
    depends_on:
      - logstash
    networks:
      - elk-network
    restart: unless-stopped

volumes:
  elasticsearch_data:
    driver: local

networks:
  elk-network:
    driver: bridge
`;

  // 3. åˆ›å»ºLogstashç®¡é“é…ç½®
  const logstashPipeline = `
input {
  beats {
    port => 5044
  }
}

filter {
  if [fields][service] == "planning-engine" {
    grok {
      match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} %{GREEDYDATA:message}" }
    }
    
    date {
      match => [ "timestamp", "ISO8601" ]
    }
    
    mutate {
      add_field => { "service" => "planning-engine" }
      add_field => { "environment" => "production" }
    }
  }
  
  if [fields][service] == "monitoring" {
    json {
      source => "message"
    }
    
    mutate {
      add_field => { "service" => "monitoring" }
      add_field => { "environment" => "production" }
    }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "%{[fields][service]}-%{+YYYY.MM.dd}"
  }
}
`;

  // 4. åˆ›å»ºFilebeaté…ç½®
  const filebeatConfig = `
filebeat.inputs:
- type: log
  enabled: true
  paths:
    - /var/log/planning-engine/*.log
  fields:
    service: planning-engine
    environment: production
  fields_under_root: true

- type: log
  enabled: true
  paths:
    - /var/log/monitoring/*.log
  fields:
    service: monitoring
    environment: production
  fields_under_root: true

output.logstash:
  hosts: ["logstash:5044"]

processors:
  - add_host_metadata:
      when.not.contains.tags: forwarded
`;

  // 5. åˆ›å»ºKibanaä»ªè¡¨æ¿é…ç½®
  const kibanaDashboard = `
{
  "version": "8.11.0",
  "objects": [
    {
      "id": "planning-engine-dashboard",
      "type": "dashboard",
      "attributes": {
        "title": "Planning Engine Dashboard",
        "panelsJSON": "[{\\"version\\":\\"8.11.0\\",\\"type\\":\\"visualization\\",\\"gridData\\":{\\"x\\":0,\\"y\\":0,\\"w\\":12,\\"h\\":8},\\"panelIndex\\":1,\\"embeddableConfig\\":{},\\"panelRefName\\":\\"panel_1\\"}]"
      }
    }
  ]
}
`;

  // 6. åˆ›å»ºæ—¥å¿—æ ¼å¼é…ç½®
  const logFormat = `
// ç»“æ„åŒ–æ—¥å¿—æ ¼å¼
const winston = require('winston');

const logger = winston.createLogger({
  level: 'info',
  format: winston.format.combine(
    winston.format.timestamp({
      format: 'YYYY-MM-DD HH:mm:ss.SSS'
    }),
    winston.format.errors({ stack: true }),
    winston.format.json()
  ),
  defaultMeta: {
    service: 'planning-engine',
    environment: process.env.NODE_ENV || 'development'
  },
  transports: [
    new winston.transports.File({
      filename: '/var/log/planning-engine/error.log',
      level: 'error'
    }),
    new winston.transports.File({
      filename: '/var/log/planning-engine/combined.log'
    }),
    new winston.transports.Console({
      format: winston.format.combine(
        winston.format.colorize(),
        winston.format.simple()
      )
    })
  ]
});

module.exports = logger;
`;

  // 7. åˆ›å»ºç›®å½•ç»“æ„
  const directories = [
    'elk',
    'elk/logstash',
    'elk/logstash/pipeline',
    'elk/logstash/config',
    'elk/filebeat',
    'elk/kibana',
    'logs/planning-engine',
    'logs/monitoring'
  ];
  
  directories.forEach(dir => {
    if (!fs.existsSync(dir)) {
      fs.mkdirSync(dir, { recursive: true });
    }
  });
  
  // 8. ä¿å­˜é…ç½®æ–‡ä»¶
  fs.writeFileSync('elk/docker-compose.yml', dockerCompose);
  fs.writeFileSync('elk/logstash/pipeline/logstash.conf', logstashPipeline);
  fs.writeFileSync('elk/filebeat/filebeat.yml', filebeatConfig);
  fs.writeFileSync('elk/kibana/dashboard.json', kibanaDashboard);
  fs.writeFileSync('elk/logger.js', logFormat);
  
  // 9. åˆ›å»ºå¯åŠ¨è„šæœ¬
  const startScript = `#!/bin/bash
# ELK Stack å¯åŠ¨è„šæœ¬

echo "ğŸš€ å¯åŠ¨ELK Stack..."

# åˆ›å»ºæ—¥å¿—ç›®å½•
mkdir -p /var/log/planning-engine
mkdir -p /var/log/monitoring

# å¯åŠ¨ELK Stack
cd elk
docker-compose up -d

# ç­‰å¾…æœåŠ¡å¯åŠ¨
echo "â³ ç­‰å¾…æœåŠ¡å¯åŠ¨..."
sleep 30

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
echo "ğŸ” æ£€æŸ¥æœåŠ¡çŠ¶æ€..."
docker-compose ps

# åˆ›å»ºç´¢å¼•
echo "ğŸ“Š åˆ›å»ºElasticsearchç´¢å¼•..."
curl -X PUT "localhost:9200/planning-engine" -H 'Content-Type: application/json' -d'
{
  "settings": {
    "number_of_shards": 1,
    "number_of_replicas": 0,
    "refresh_interval": "5s"
  }
}'

curl -X PUT "localhost:9200/monitoring" -H 'Content-Type: application/json' -d'
{
  "settings": {
    "number_of_shards": 1,
    "number_of_replicas": 0,
    "refresh_interval": "1s"
  }
}'

echo "âœ… ELK Stack å¯åŠ¨å®Œæˆï¼"
echo "ğŸ“Š Kibana: http://localhost:5601"
echo "ğŸ” Elasticsearch: http://localhost:9200"
`;

  fs.writeFileSync('elk/start.sh', startScript);
  
  // 10. åˆ›å»ºç›‘æ§è„šæœ¬
  const monitorScript = `#!/bin/bash
# ELK Stack ç›‘æ§è„šæœ¬

echo "ğŸ“Š ELK Stack ç›‘æ§çŠ¶æ€..."

# æ£€æŸ¥Elasticsearch
echo "ğŸ” æ£€æŸ¥Elasticsearch..."
curl -s "localhost:9200/_cluster/health" | jq '.'

# æ£€æŸ¥Logstash
echo "ğŸ” æ£€æŸ¥Logstash..."
curl -s "localhost:9600/_node/stats" | jq '.'

# æ£€æŸ¥Kibana
echo "ğŸ” æ£€æŸ¥Kibana..."
curl -s "localhost:5601/api/status" | jq '.'

# æ£€æŸ¥Filebeat
echo "ğŸ” æ£€æŸ¥Filebeat..."
docker exec athlete-ally-filebeat filebeat test output

echo "âœ… ç›‘æ§å®Œæˆï¼"
`;

  fs.writeFileSync('elk/monitor.sh', monitorScript);
  
  console.log('âœ… ELK Stacké…ç½®å®Œæˆï¼');
  console.log('ğŸ“ é…ç½®æ–‡ä»¶å·²åˆ›å»º:');
  console.log('   - elk/docker-compose.yml');
  console.log('   - elk/logstash/pipeline/logstash.conf');
  console.log('   - elk/filebeat/filebeat.yml');
  console.log('   - elk/kibana/dashboard.json');
  console.log('   - elk/logger.js');
  console.log('   - elk/start.sh');
  console.log('   - elk/monitor.sh');
  
  console.log('\nğŸš€ å¯åŠ¨ELK Stack:');
  console.log('   cd elk && ./start.sh');
  
  console.log('\nğŸ“Š è®¿é—®åœ°å€:');
  console.log('   - Kibana: http://localhost:5601');
  console.log('   - Elasticsearch: http://localhost:9200');
  
  console.log('\nğŸ’¡ ä½¿ç”¨å»ºè®®:');
  console.log('1. å®šæœŸæ¸…ç†æ—§æ—¥å¿—ç´¢å¼•');
  console.log('2. ç›‘æ§ç£ç›˜ä½¿ç”¨æƒ…å†µ');
  console.log('3. é…ç½®æ—¥å¿—è½®è½¬');
  console.log('4. è®¾ç½®å‘Šè­¦è§„åˆ™');
  console.log('5. ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½');
  console.log('6. å®æ–½æ—¥å¿—åˆ†æ');
  console.log('7. å»ºç«‹æ—¥å¿—å®¡è®¡');
  console.log('8. é…ç½®æ—¥å¿—å¤‡ä»½');
  
  return elkConfig;
};

// è¿è¡ŒELK Stackè®¾ç½®
const result = setupELKStack();
console.log('\nğŸ‰ ELK Stackæ—¥å¿—èšåˆè®¾ç½®å®Œæˆï¼');

